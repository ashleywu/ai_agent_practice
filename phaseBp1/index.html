<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aha! Catcher</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            max-width: 600px;
            width: 100%;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
            font-size: 2.5em;
            font-weight: 700;
        }

        .status {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 1.1em;
            min-height: 24px;
        }

        .status.recording {
            color: #e74c3c;
            font-weight: 600;
        }

        .status.processing {
            color: #3498db;
            font-weight: 600;
        }

        .capture-button {
            width: 100%;
            padding: 30px;
            font-size: 2em;
            font-weight: 700;
            color: white;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: none;
            border-radius: 15px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
            margin-bottom: 30px;
        }

        .capture-button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.6);
        }

        .capture-button:active:not(:disabled) {
            transform: translateY(0);
        }

        .capture-button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        .results {
            margin-top: 30px;
            display: none;
        }

        .results.show {
            display: block;
        }

        .result-section {
            margin-bottom: 25px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
            border-left: 4px solid #667eea;
        }

        .result-section h2 {
            color: #333;
            margin-bottom: 15px;
            font-size: 1.5em;
            font-weight: 600;
        }

        .result-section p {
            color: #555;
            line-height: 1.6;
            font-size: 1.1em;
        }

        .error {
            background: #fee;
            border-left-color: #e74c3c;
            color: #c0392b;
        }

        .error h2 {
            color: #c0392b;
        }

        .loading {
            text-align: center;
            color: #666;
            font-style: italic;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Aha! Catcher</h1>
        <div id="status" class="status">Ready to capture</div>
        <div id="instructions" class="instructions" style="text-align: center; color: #666; font-size: 0.9em; margin: 10px 0 20px 0; padding: 10px; background: #f0f0f0; border-radius: 8px;">
            <strong>ä½¿ç”¨è¯´æ˜ï¼š</strong>åº”ç”¨å·²åœ¨åå°å½•éŸ³ï¼ˆä¿å­˜æœ€å30ç§’ï¼‰ã€‚<br>
            ç›´æ¥è¯´è¯ â†’ è¯´å®Œåç‚¹å‡»æŒ‰é’® â†’ æŸ¥çœ‹ç»“æœ
        </div>
        
        <button id="captureButton" class="capture-button">
            Capture Aha!
        </button>

        <div id="results" class="results">
            <div id="transcriptionSection" class="result-section">
                <h2>Transcription</h2>
                <p id="transcriptionText" class="loading">Processing...</p>
            </div>
            
            <div id="researchSection" class="result-section">
                <h2>Research Summary</h2>
                <p id="researchText" class="loading">Processing...</p>
            </div>
        </div>
    </div>

    <script>
        // Configuration - use relative API path when deployed, localhost proxy for development
        // The FastAPI server handles CORS and API key security
        const isLocalhost = window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1';
        const proxyPort = window.location.port || '8080'; // Default port 8080 for dev server
        // Use relative path when deployed (same origin), or localhost proxy for development
        const API_BASE_URL = isLocalhost 
            ? `http://localhost:${proxyPort}/api`  // Use proxy server on current port for dev
            : '/api';  // Use relative path when deployed (same origin, no CORS)
        const API_KEY = ''; // Not needed - API key is handled server-side
        
        // Debug logging
        console.log('API Configuration:');
        console.log('  Hostname:', window.location.hostname);
        console.log('  Port:', window.location.port);
        console.log('  Protocol:', window.location.protocol);
        console.log('  API_BASE_URL:', API_BASE_URL);
        console.log('  isLocalhost:', isLocalhost);
        
        // Warn if accessing via file:// protocol
        if (window.location.protocol === 'file:') {
            console.error('âš ï¸ WARNING: Opening HTML file directly (file://) will cause CORS errors!');
            console.error('âš ï¸ Please access through the proxy server: python server.py');
            console.error('âš ï¸ Then open: http://localhost:8080');
        }
        
        // Log current configuration
        console.log('=== Aha! Catcher Configuration ===');
        console.log(`Protocol: ${window.location.protocol}`);
        console.log(`Hostname: ${window.location.hostname}`);
        console.log(`Port: ${window.location.port || '8080 (default)'}`);
        console.log(`API Base URL: ${API_BASE_URL}`);
        console.log('===================================');

        // Audio recording state
        let mediaRecorder = null;
        let audioChunks = [];
        let audioBuffer = [];
        const BUFFER_DURATION = 30000; // 30 seconds in milliseconds
        let recordingStartTime = null;
        let isRecording = false;

        // DOM elements
        const captureButton = document.getElementById('captureButton');
        const statusDiv = document.getElementById('status');
        const resultsDiv = document.getElementById('results');
        const transcriptionText = document.getElementById('transcriptionText');
        const researchText = document.getElementById('researchText');
        
        // Initial instructions
        function setInitialInstructions() {
            updateInstructions(`
                <strong>ğŸ“ ä½¿ç”¨æµç¨‹ï¼š</strong><br>
                1ï¸âƒ£ åº”ç”¨å·²åœ¨åå°æŒç»­å½•éŸ³ï¼ˆä¿å­˜æœ€å30ç§’ï¼‰<br>
                2ï¸âƒ£ <strong>ç›´æ¥å¼€å§‹è¯´è¯</strong> - ä¸éœ€è¦å…ˆç‚¹å‡»æŒ‰é’®<br>
                3ï¸âƒ£ è¯´å®Œåç‚¹å‡» <strong>"Capture Aha!"</strong> æŒ‰é’®<br>
                4ï¸âƒ£ æŸ¥çœ‹è½¬å½•ç»“æœå’Œç ”ç©¶æ‘˜è¦
            `);
        }

        // Initialize audio recording
        async function initializeRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000
                    } 
                });

                // Create MediaRecorder with options - prefer M4A/AAC format for API compatibility
                const options = {
                    mimeType: 'audio/webm;codecs=opus',
                    audioBitsPerSecond: 64000 // 64 kbps for smaller file size
                };

                // Try to use M4A/AAC if supported (better API compatibility)
                const preferredFormats = [
                    'audio/mp4;codecs=mp4a.40.2', // M4A/AAC
                    'audio/mp4', // M4A
                    'audio/webm;codecs=opus', // WebM Opus
                    'audio/webm' // WebM fallback
                ];
                
                for (const format of preferredFormats) {
                    if (MediaRecorder.isTypeSupported(format)) {
                        options.mimeType = format;
                        console.log(`Using audio format: ${format}`);
                        break;
                    }
                }
                
                // Fallback to default if none supported
                if (!options.mimeType || options.mimeType === 'audio/webm;codecs=opus') {
                    console.warn('Falling back to default MediaRecorder format');
                }

                mediaRecorder = new MediaRecorder(stream, options);

                // Continuously record and maintain 30-second buffer
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data && event.data.size > 0) {
                        const chunk = {
                            data: event.data,
                            timestamp: Date.now()
                        };
                        audioBuffer.push(chunk);

                        // Remove chunks older than 30 seconds (with some margin)
                        const now = Date.now();
                        const maxAge = BUFFER_DURATION + 5000; // Keep 35 seconds to ensure we have enough
                        const beforeLength = audioBuffer.length;
                        audioBuffer = audioBuffer.filter(chunk => 
                            now - chunk.timestamp < maxAge
                        );
                        
                        if (audioBuffer.length < beforeLength) {
                            console.log(`Cleaned ${beforeLength - audioBuffer.length} old chunks`);
                        }
                        
                        console.log(`Audio chunk received: ${event.data.size} bytes, buffer has ${audioBuffer.length} chunks (~${Math.round(audioBuffer.length)} seconds)`);
                    } else {
                        console.warn('Received empty audio chunk');
                    }
                };

                // Handle recording errors
                mediaRecorder.onerror = (event) => {
                    console.error('MediaRecorder error:', event.error);
                    updateStatus('Recording error occurred. Please try again.', 'error');
                    isRecording = false;
                };

                // Handle recording stop
                mediaRecorder.onstop = () => {
                    console.log('Recording stopped unexpectedly');
                    console.log(`Buffer had ${audioBuffer.length} chunks when stopped`);
                    // Don't set isRecording = false here, as we want to restart if needed
                    // The recording might have stopped due to browser optimization
                };

                // Start continuous recording with 1-second slices for better buffer management
                // Use timeslice to ensure regular data availability
                mediaRecorder.start(1000); // Collect data every second
                
                // Monitor recording state to prevent unexpected stops
                const stateCheckInterval = setInterval(() => {
                    if (mediaRecorder && mediaRecorder.state === 'inactive' && isRecording) {
                        console.warn('MediaRecorder stopped unexpectedly, restarting...');
                        try {
                            if (mediaRecorder.state === 'inactive') {
                                mediaRecorder.start(1000);
                                console.log('Recording restarted');
                            }
                        } catch (e) {
                            console.error('Failed to restart recording:', e);
                            // Try to reinitialize
                            initializeRecording().catch(err => {
                                console.error('Failed to reinitialize recording:', err);
                            });
                        }
                    }
                }, 2000); // Check every 2 seconds
                
                // Store interval ID for cleanup
                if (window.recordingStateCheckInterval) {
                    clearInterval(window.recordingStateCheckInterval);
                }
                window.recordingStateCheckInterval = stateCheckInterval;
                isRecording = true;
                recordingStartTime = Date.now();
                
                updateStatus('Recording... (buffer: last 30 seconds)', 'recording');
                
                // Log recording status
                console.log('Recording started successfully');
                console.log(`MediaRecorder state: ${mediaRecorder.state}`);
                console.log(`Audio format: ${options.mimeType}`);
                
            } catch (error) {
                console.error('Error accessing microphone:', error);
                isRecording = false; // Ensure flag is reset on error
                updateStatus('Error: Could not access microphone. Please check permissions.', 'error');
                captureButton.disabled = false; // Keep button enabled so user can retry
            }
        }

        // Update status display
        function updateStatus(message, className = '') {
            statusDiv.textContent = message;
            statusDiv.className = 'status ' + className;
        }
        
        // Update instructions display
        function updateInstructions(message) {
            const instructionsDiv = document.getElementById('instructions');
            if (instructionsDiv) {
                instructionsDiv.innerHTML = message.replace(/\n/g, '<br>');
            }
        }

        // Convert audio buffer to Blob
        function getAudioBlob() {
            // Combine all chunks in the buffer (last 30 seconds)
            const chunks = audioBuffer.map(chunk => chunk.data);
            
            if (chunks.length === 0) {
                console.error('Audio buffer is empty');
                console.error(`isRecording: ${isRecording}`);
                console.error(`mediaRecorder state: ${mediaRecorder ? mediaRecorder.state : 'null'}`);
                throw new Error('No audio data in buffer. Please wait a moment and try again.');
            }
            
            // Calculate actual buffer duration
            if (audioBuffer.length > 0) {
                const oldestChunk = audioBuffer[0];
                const newestChunk = audioBuffer[audioBuffer.length - 1];
                const actualDuration = (newestChunk.timestamp - oldestChunk.timestamp) / 1000;
                console.log(`Buffer duration: ${actualDuration.toFixed(1)} seconds`);
                
                // Warn if buffer is too short
                if (actualDuration < 5) {
                    console.warn(`Warning: Buffer is very short (${actualDuration.toFixed(1)}s). Recording may have started recently.`);
                }
            }
            
            // Determine MIME type from the first chunk or use default
            let mimeType = 'audio/webm';
            if (chunks.length > 0 && chunks[0].type) {
                mimeType = chunks[0].type;
            } else if (mediaRecorder && mediaRecorder.mimeType) {
                mimeType = mediaRecorder.mimeType;
            }
            
            // Create a blob from all buffered chunks
            const blob = new Blob(chunks, { type: mimeType });
            
            // Log buffer info for debugging
            const bufferDuration = audioBuffer.length; // Approximate seconds
            console.log(`Audio buffer: ${bufferDuration} chunks, ${blob.size} bytes, type: ${mimeType}`);
            console.log(`Estimated duration: ~${bufferDuration} seconds`);
            
            // Validate blob size (very small blobs might be corrupted)
            if (blob.size < 1000) {
                console.warn(`Warning: Audio blob is very small (${blob.size} bytes). This might indicate a problem.`);
            }
            
            return blob;
        }

        // Send audio to transcription API
        async function transcribeAudio(audioBlob) {
            const formData = new FormData();
            
            // Determine file extension based on MIME type
            let fileExtension = 'webm';
            if (audioBlob.type.includes('mp4') || audioBlob.type.includes('m4a')) {
                fileExtension = 'm4a';
            } else if (audioBlob.type.includes('webm')) {
                fileExtension = 'webm';
            } else if (audioBlob.type.includes('wav')) {
                fileExtension = 'wav';
            }
            
            console.log(`Audio blob type: ${audioBlob.type}, size: ${audioBlob.size} bytes`);
            formData.append('audio_file', audioBlob, `recording.${fileExtension}`);
            
            // Add language hint to improve accuracy (Chinese/English)
            // API supports: 'en', 'zh-CN', 'zh-TW', etc.
            formData.append('language', 'zh-CN'); // Default to Chinese, can detect English too

            console.log(`Sending transcription request to: ${API_BASE_URL}/v1/audio/transcriptions`);
            console.log(`Audio blob size: ${audioBlob.size} bytes`);
            console.log(`Using proxy: ${isLocalhost}`);

            try {
                // Build headers - only add Authorization if not using proxy
                const headers = {};
                if (!isLocalhost) {
                    headers['Authorization'] = `Bearer ${API_KEY}`;
                }
                // Don't set Content-Type - browser sets it automatically with boundary for FormData

                const response = await fetch(`${API_BASE_URL}/v1/audio/transcriptions`, {
                    method: 'POST',
                    headers: headers,
                    body: formData
                });

                console.log(`Response status: ${response.status}`);

                if (!response.ok) {
                    let errorText;
                    try {
                        errorText = await response.text();
                    } catch (e) {
                        errorText = `HTTP ${response.status}: ${response.statusText}`;
                    }
                    throw new Error(`Transcription failed: ${response.status} - ${errorText}`);
                }

                const result = await response.json();
                console.log('Transcription successful:', result);
                return result;
            } catch (error) {
                // Handle network/CORS errors
                if (error.name === 'TypeError' && error.message.includes('fetch')) {
                    throw new Error(`Network error: ${error.message}. This may be a CORS issue. Make sure the API server allows requests from your origin.`);
                }
                throw error;
            }
        }

        // Get research summary using chat completions
        async function getResearchSummary(transcription) {
            const requestBody = {
                model: 'supermind-agent-v1',
                messages: [
                    {
                        role: 'system',
                        content: 'You are a helpful research assistant. When given a transcribed "Aha!" moment or idea, identify the core concept and perform relevant web searches to provide a concise research summary. Focus on the key insight and provide 2-3 relevant findings.'
                    },
                    {
                        role: 'user',
                        content: `Here's an "Aha!" moment that was captured:\n\n"${transcription}"\n\nPlease identify the core concept and provide a concise research summary with relevant findings.`
                    }
                ],
                temperature: 0.7,
                max_tokens: 500
            };

            console.log(`Sending research summary request to: ${API_BASE_URL}/v1/chat/completions`);

            try {
                // Build headers - only add Authorization if not using proxy
                const headers = {
                    'Content-Type': 'application/json'
                };
                if (!isLocalhost) {
                    headers['Authorization'] = `Bearer ${API_KEY}`;
                }

                const response = await fetch(`${API_BASE_URL}/v1/chat/completions`, {
                    method: 'POST',
                    headers: headers,
                    body: JSON.stringify(requestBody)
                });

                console.log(`Response status: ${response.status}`);

                if (!response.ok) {
                    let errorText;
                    try {
                        errorText = await response.text();
                    } catch (e) {
                        errorText = `HTTP ${response.status}: ${response.statusText}`;
                    }
                    throw new Error(`Research summary failed: ${response.status} - ${errorText}`);
                }

                const data = await response.json();
                console.log('Research summary successful');
                return data.choices[0].message.content;
            } catch (error) {
                // Handle network/CORS errors
                if (error.name === 'TypeError' && error.message.includes('fetch')) {
                    throw new Error(`Network error: ${error.message}. This may be a CORS issue.`);
                }
                throw error;
            }
        }

        // Handle capture button click
        async function handleCapture() {
            // Ensure recording is active
            if (!isRecording || !mediaRecorder || mediaRecorder.state === 'inactive') {
                updateStatus('Starting recording...', 'processing');
                try {
                    await initializeRecording();
                    // Wait for buffer to accumulate (at least 2 seconds)
                    updateStatus('Recording... Please wait a moment for buffer to fill.', 'recording');
                    await new Promise(resolve => setTimeout(resolve, 2000));
                    
                    // Check if we have data now
                    if (audioBuffer.length === 0) {
                        updateStatus('Waiting for audio data... Please speak or make some sound.', 'recording');
                        // Wait a bit more
                        await new Promise(resolve => setTimeout(resolve, 2000));
                    }
                    
                    if (audioBuffer.length === 0) {
                        throw new Error('No audio detected. Please check your microphone and try again.');
                    }
                    
                    updateStatus('Ready! Click again to capture.', '');
                    return; // User needs to click again to capture
                } catch (error) {
                    console.error('Failed to initialize recording:', error);
                    updateStatus(`Error: ${error.message}`, 'error');
                    return;
                }
            }

            // Check if we have audio data before proceeding
            if (audioBuffer.length === 0) {
                updateStatus('No audio in buffer. Please wait a moment and try again.', 'error');
                // Wait and retry once
                await new Promise(resolve => setTimeout(resolve, 2000));
                if (audioBuffer.length === 0) {
                    updateStatus('Still no audio. Please check your microphone permissions.', 'error');
                    return;
                }
            }

            // Disable button during processing
            captureButton.disabled = true;
            updateStatus('Processing audio...', 'processing');
            resultsDiv.classList.add('show');
            transcriptionText.textContent = 'Transcribing audio...';
            researchText.textContent = 'Waiting for transcription...';

            try {
                // Ensure recording is still active before capturing
                if (mediaRecorder && mediaRecorder.state === 'inactive') {
                    console.warn('MediaRecorder was inactive, restarting...');
                    mediaRecorder.start(1000);
                    await new Promise(resolve => setTimeout(resolve, 1000));
                }
                
                // Get the last 30 seconds of audio
                const audioBlob = getAudioBlob();
                
                if (!audioBlob || audioBlob.size === 0) {
                    throw new Error('No audio data captured. Please try again.');
                }
                
                // Validate audio blob size (should be at least a few KB for meaningful audio)
                const minSize = 5000; // 5KB minimum
                if (audioBlob.size < minSize) {
                    console.warn(`Audio blob is very small (${audioBlob.size} bytes). This might result in poor transcription.`);
                    updateStatus('Warning: Very short audio detected. Results may be incomplete.', 'processing');
                }

                console.log(`Sending audio blob: ${audioBlob.size} bytes`);

                // Step 1: Transcribe audio
                updateStatus('Transcribing audio...', 'processing');
                const transcriptionResult = await transcribeAudio(audioBlob);
                const transcribedText = transcriptionResult.text || 'No transcription available';
                
                transcriptionText.textContent = transcribedText;
                transcriptionText.classList.remove('loading');

                // Step 2: Get research summary
                updateStatus('Generating research summary...', 'processing');
                researchText.textContent = 'Analyzing and researching...';
                
                const researchSummary = await getResearchSummary(transcribedText);
                researchText.textContent = researchSummary;
                researchText.classList.remove('loading');

                updateStatus('Complete! Ready for next capture.', '');

            } catch (error) {
                console.error('Error processing audio:', error);
                const errorMessage = error.message || 'Unknown error occurred';
                updateStatus(`Error: ${errorMessage}`, 'error');
                
                // Show detailed error in transcription section
                transcriptionText.textContent = `Error: ${errorMessage}`;
                transcriptionText.parentElement.classList.add('error');
                transcriptionText.classList.remove('loading');
                
                researchText.textContent = 'Research summary unavailable due to transcription error.';
                researchText.classList.remove('loading');
            } finally {
                // Re-enable button
                captureButton.disabled = false;
            }
        }

        // Event listener
        captureButton.addEventListener('click', handleCapture);

        // Update buffer status display periodically
        function updateBufferStatus() {
            if (audioBuffer.length > 0) {
                const oldestChunk = audioBuffer[0];
                const newestChunk = audioBuffer[audioBuffer.length - 1];
                const duration = Math.min((newestChunk.timestamp - oldestChunk.timestamp) / 1000, 30);
                const statusText = `âœ… å½•éŸ³ä¸­... (å·²ç¼“å†²${Math.round(duration)}ç§’)`;
                if (statusDiv.textContent.includes('å½•éŸ³') || statusDiv.textContent.includes('Recording')) {
                    updateStatus(statusText, 'recording');
                }
                updateInstructionsForBuffer(duration);
            }
        }
        
        // Update instructions when buffer status changes
        function updateInstructionsForBuffer(duration) {
            if (duration >= 5) {
                updateInstructions(`âœ… å½•éŸ³ä¸­... (å·²ç¼“å†²${Math.round(duration)}ç§’) <strong>å¯ä»¥ç›´æ¥å¼€å§‹è¯´è¯ï¼Œè¯´å®Œåç‚¹å‡»æŒ‰é’®</strong>`);
            } else if (duration > 0) {
                updateInstructions(`â³ æ­£åœ¨ç¼“å†²ä¸­... (${Math.round(duration)}ç§’) è¯·ç¨ç­‰ç‰‡åˆ»å†å¼€å§‹è¯´è¯`);
            }
        }
        
        // Start buffer status updates
        let bufferStatusInterval = null;
        function startBufferStatusUpdates() {
            if (bufferStatusInterval) {
                clearInterval(bufferStatusInterval);
            }
            bufferStatusInterval = setInterval(updateBufferStatus, 2000); // Update every 2 seconds
        }
        
        function stopBufferStatusUpdates() {
            if (bufferStatusInterval) {
                clearInterval(bufferStatusInterval);
                bufferStatusInterval = null;
            }
        }

        // Initialize on page load - start recording immediately
        window.addEventListener('load', async () => {
            setInitialInstructions(); // Show initial instructions
            updateStatus('æ­£åœ¨åˆå§‹åŒ–éº¦å…‹é£...', '');
            try {
                await initializeRecording();
                startBufferStatusUpdates(); // Start showing buffer status
                // Wait a moment for initial buffer
                await new Promise(resolve => setTimeout(resolve, 2000));
                if (audioBuffer.length > 0) {
                    const duration = Math.min(audioBuffer.length, 30);
                    updateStatus(`âœ… å½•éŸ³ä¸­... (å·²ç¼“å†²${duration}ç§’) ç›´æ¥è¯´è¯ï¼Œè¯´å®Œåç‚¹å‡»æŒ‰é’®`, 'recording');
                    updateInstructions('ğŸ’¡ <strong>ç°åœ¨å¯ä»¥ç›´æ¥å¼€å§‹è¯´è¯äº†ï¼</strong> åº”ç”¨æ­£åœ¨åå°å½•éŸ³ã€‚è¯´å®Œåç‚¹å‡»"Capture Aha!"æŒ‰é’®å³å¯ã€‚');
                } else {
                    updateStatus('âœ… å‡†å¤‡å°±ç»ªï¼è¯·å¼€å§‹è¯´è¯ï¼Œè¯´å®Œåç‚¹å‡»æŒ‰é’®', '');
                    updateInstructions('ğŸ’¡ <strong>ç°åœ¨å¯ä»¥ç›´æ¥å¼€å§‹è¯´è¯äº†ï¼</strong> åº”ç”¨æ­£åœ¨åå°å½•éŸ³ã€‚è¯´å®Œåç‚¹å‡»"Capture Aha!"æŒ‰é’®å³å¯ã€‚');
                }
            } catch (error) {
                console.error('Failed to initialize on load:', error);
                updateStatus('ç‚¹å‡» "Capture Aha!" å¼€å§‹å½•éŸ³', '');
                updateInstructions('âŒ æ— æ³•è®¿é—®éº¦å…‹é£ã€‚è¯·æ£€æŸ¥æµè§ˆå™¨æƒé™è®¾ç½®ã€‚');
            }
        });
        
        // Keep recording active when page is visible
        document.addEventListener('visibilitychange', () => {
            if (document.visibilityState === 'visible' && !isRecording && mediaRecorder) {
                console.log('Page became visible, checking recording state...');
                if (mediaRecorder.state === 'inactive') {
                    console.log('Restarting recording...');
                    initializeRecording().catch(err => {
                        console.error('Failed to restart recording:', err);
                    });
                }
            }
        });

        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            // Stop buffer status updates
            stopBufferStatusUpdates();
            
            // Clear state check interval
            if (window.recordingStateCheckInterval) {
                clearInterval(window.recordingStateCheckInterval);
                window.recordingStateCheckInterval = null;
            }
            
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
            }
        });
        
        // Prevent page from going to sleep (keeps recording active)
        if ('wakeLock' in navigator) {
            let wakeLock = null;
            async function requestWakeLock() {
                try {
                    wakeLock = await navigator.wakeLock.request('screen');
                    console.log('Wake lock acquired to keep recording active');
                } catch (err) {
                    console.warn('Wake lock not available:', err);
                }
            }
            requestWakeLock();
            
            // Re-request wake lock if it's released
            document.addEventListener('visibilitychange', async () => {
                if (wakeLock !== null && document.visibilityState === 'visible') {
                    await requestWakeLock();
                }
            });
        }
    </script>
</body>
</html>
